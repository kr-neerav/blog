+++
title = 'Ch07'
date = 2024-12-31T10:32:18-08:00
draft = true
+++
* a lakehouse can handle the entire lifecycle of structured and unstructure data, combining the best of data lake and DWH approaches.
* DWH and Data Lake meet the needs for different users. An organization that has both type of users faced challenges.
* Anti pattern - Disconnected Systems: due to different needs organizations maintain separate DWH and Data Lake. Higher operational cost. Two systems can cause data quality and consistency problems. Also effort to transform data from one system to use it along side in other may put off end users completely e.g. analytic friendly metrics are not easily queryable in the science ecosystem.
* Anti pattern - Duplicated data: how about building a platform capability that syncs data from data lake. so all data is centrally managed in data lake and some data in synced to DWH. This faces data governance challenges with DWH can implement its own governance policy or data governance needs to be repeated for each DWH. Challenging to audit if there are multiple DWH. 
## Converged Architecture
* DWH and data lake share a common storage. Two different compute engine SQL for DWH and distributed programming for data lake read/process data without moving it around.
* use open table format for storage so both DWH and Spark can read it.
* This is a comprimise. A data lake is slower/costlier on SQL workloads than a DWH (as DWH stores data in propriety format for compute performance) and DWH is slower/costlier on Spark/ML workloads than a data lake (as bulk data reading capability not available from DWH, unstructured data not supported)
* Build a lakehouse on a data lake if majority of the users/usecases are for engineering/science. Build a lakehouse on DWH if majority of the users/usecases are for analyst.
* 
